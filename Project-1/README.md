# Проект 1. Анализ вакансий из HeadHunter

## Оглавление  
[1. Описание проекта](https://github.com/CorhariS/sf_data_science/tree/main/Project-1/README.md#Описание-проекта)  
[2. Какой кейс решаем?](https://github.com/CorhariS/sf_data_science/tree/main/Project-1/README.md#Какой-кейс-решаем)  
[3. Краткая информация о данных](https://github.com/CorhariS/sf_data_science/tree/main/Project-1/README.md#Краткая-информация-о-данных)  
[4. Этапы работы над проектом](https://github.com/CorhariS/sf_data_science/tree/main/Project-1/README.md#Этапы-работы-над-проектом)  
[5. Результат](https://github.com/CorhariS/sf_data_science/tree/main/Project-1/README.md#Результат)    
[6. Выводы](https://github.com/CorhariS/sf_data_science/tree/main/Project-1/README.md#Выводы) 

### Описание проекта    
Необходимо провести анализ базы резюме соискателей, выгруженной с сайта поиска вакансий hh.ru

:arrow_up:[к оглавлению](https://github.com/CorhariS/sf_data_science/tree/main/Project-1/README.md#Оглавление)


### Какой кейс решаем? 
Провести базовый анализ структуры исходных данных, сделать необходимые преобразования и провести расведывательный анализ данных.
При выполнеии проекта необходимо:    -      
- Внимательно изучить детали задачи.
- Скачать исходный датасет
- Решение оформить только в Jupyter Notebook
- Решение должно использовать только переменные, основные структуры данных (списки, словари, множества), циклы, функции, 
    библиотеки numpy, pandas, matplotlib, seaborn, plotly. 
- Ответить на все контрольные вопросы на платформе

**Что практикуем**     
Учимся писать хороший код на python в Jupyter Notebook


### Краткая информация о данных
Исходные данные были взяты с сайта hh.ru и в настоящий момент их можно скачать по следйющей ссылке https://drive.google.com/file/d/1AO4z4YSb-qIsWDpz5Vt4uFrGZ8E9PK1D/view?usp=sharing
Так же были использованы данные по курсам валют за 2019 год. Ссылка https://drive.google.com/file/d/14kyThxNgP99YBLJecS60MaIzMXZiMTGG/view?usp=sharing
  
:arrow_up:[к оглавлению](https://github.com/CorhariS/sf_data_science/tree/main/Project-1/README.md#Оглавление)


### Этапы работы над проектом  
- Этап 1. Подготовка исходных данных.
- Этап 2. базовый анализ структуры данных.
- Этап 3. преобразование данных.
- Этап 4. разведывательный анализ.
- Этап 5. очистка данных.

:arrow_up:[к оглавлению](https://github.com/CorhariS/sf_data_science/tree/main/Project-1/README.md#Оглавление)


### Результаты:  
Полученные результаты показывают, что наша итоговая база резюме соискателей, содержит только уникальные записи, очищенные от "мусора" и по ней проведен предварительный анализ.
Графические результаты проекта представлены в папке \plotly

:arrow_up:[к оглавлению](https://github.com/CorhariS/sf_data_science/tree/main/Project-1/README.md#Оглавление)


### Выводы:  
Согласно поставленной задаче, итоговый датасет подходит для построении модели, которая бы автоматически определяла примерный уровень заработной платы, подходящей пользователю, исходя из информации, которую он указал о себе.

:arrow_up:[к оглавлению](https://github.com/CorhariS/sf_data_science/tree/main/Project-1/README.md#Оглавление)

